# ============================================================
# HYBRID RAG SYSTEM - Dependencies
# Vector Search + Knowledge Graph + LLM Integration
# ============================================================

# ----------------------------
# Core Data Processing
# ----------------------------
pandas>=2.1.4
numpy>=1.26.0

# ----------------------------
# Embedding Models (Semantic Search)
# ----------------------------
sentence-transformers>=2.5.1
huggingface-hub>=0.20.3
transformers>=4.38.0
tokenizers>=0.15.2
safetensors>=0.4.2

# ----------------------------
# Vector Database (ChromaDB)
# ----------------------------
chromadb>=0.4.24
# Persistent storage for document embeddings

# ----------------------------
# LLM Framework (LangChain)
# ----------------------------
langchain>=0.1.0
langchain-community>=0.0.10
langchain-core>=0.1.0
# Provides: Ollama integration, GraphCypherQAChain, and community tools

# ----------------------------
# Knowledge Graph (Neo4j)
# ----------------------------
neo4j>=5.14.1
# Official Neo4j Python driver for graph database operations

# ----------------------------
# Local LLM (Ollama)
# ----------------------------
# Note: Ollama itself is installed separately:
#   - macOS/Linux: https://ollama.ai/download
#   - After install: ollama pull llama3
# Python client comes with langchain-community

# ----------------------------
# NLP Preprocessing (Optional)
# ----------------------------
spacy>=3.7.4
# After pip install, download model:
# python -m spacy download en_core_web_sm

# ----------------------------
# File Format Support
# ----------------------------
openpyxl>=3.1.2          # Excel (.xlsx)
xlrd>=2.0.1              # Excel (.xls) - legacy format

# ----------------------------
# Performance (Optional - GPU acceleration)
# ----------------------------
# Uncomment if you have CUDA-capable GPU:
# torch>=2.1.0+cu118
# For CPU-only (default):
torch>=2.1.0
flask>=2.3.0
flask-cors>=4.0.0
python-dotenv>=1.0.0
